{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6mSkY4wFg+tA5Xp+mzAQV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Data loading (ISOT)"],"metadata":{"id":"7gbk3gIZBI_i"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import pickle\n","from sklearn.model_selection import train_test_split\n","\n","\n","real_df = pd.read_csv('real_clean.csv')\n","real = real_df['text'].values.tolist()\n","fake_df = pd.read_csv('Fake.csv')\n","fake = fake_df['text'].values.tolist()\n","real_examples = [str(x) for x in real]\n","fake_examples = [str(x) for x in fake]\n","\n","\n","\n","\n","print(f\"Loading data...\")\n","real_labels = [1] * len(real_examples)\n","fake_labels = [0] * len(fake_examples)\n","\n","X = real_examples + fake_examples\n","y = real_labels + fake_labels\n","\n","# Loop over the dataset to use tokenizer and truncate or zero pad\n","X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=42)"],"metadata":{"id":"xqEYMK7bBHX6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BASELINE 1"],"metadata":{"id":"1GOIAHRzXwNL"}},{"cell_type":"code","source":["total_full_stop_train = []\n","\n","for article in X_train:\n","    full_stop_count = 0\n","    for word in article:\n","        full_stop_count += word.count('.')\n","    total_full_stop_train.append(full_stop_count)"],"metadata":{"id":"Pgjs15q4WfQr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dat_size = len(total_full_stop_train)\n","pos = sum(total_full_stop_train[:int(dat_size/2)]) / (dat_size/2)\n","neg = sum(total_full_stop_train[int(dat_size/2):]) / (dat_size/2)\n","print(pos)\n","print(neg)\n","boundary = (pos + neg) / 2\n","print(boundary)"],"metadata":{"id":"IXWklgcCavrz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_full_stop_val = []\n","\n","for article in X_val:\n","    full_stop_count = 0\n","    for word in str(article):\n","        full_stop_count += word.count('.')\n","    total_full_stop_val.append(full_stop_count)"],"metadata":{"id":"PT2lJN6NlNAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","predictions = [0 if x > boundary else 1 for x in total_full_stop_val]\n","\n","acc = accuracy_score(y_val, predictions)\n","prec = precision_score(y_val, predictions)\n","rec = recall_score(y_val, predictions)\n","f1 = f1_score(y_val, predictions)\n","\n","print('Accuracy: ', acc)\n","print('Precision: ', prec)\n","print('Recall: ', rec)\n","print('F1 Score: ', f1)"],"metadata":{"id":"ewGx422PlORx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_full_stop_test = []\n","\n","for article in X_test:\n","    full_stop_count = 0\n","    for word in str(article):\n","        full_stop_count += word.count('.')\n","    total_full_stop_test.append(full_stop_count)"],"metadata":{"id":"AqPW3yp3e8bz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictions = [0 if x > boundary else 1 for x in total_full_stop_test]\n","\n","acc = accuracy_score(y_test, predictions)\n","prec = precision_score(y_test, predictions)\n","rec = recall_score(y_test, predictions)\n","f1 = f1_score(y_test, predictions)\n","\n","print('Accuracy: ', acc)\n","print('Precision: ', prec)\n","print('Recall: ', rec)\n","print('F1 Score: ', f1)"],"metadata":{"id":"gUyDhHt8b5kI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BASELINE 2"],"metadata":{"id":"_PvZcyMvWfiO"}},{"cell_type":"code","source":["import gensim\n","import gensim.downloader\n","\n","word2vec = gensim.downloader.load('word2vec-google-news-300')"],"metadata":{"id":"FA622ZF3Wcyz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import numpy as np\n","\n","def score(model, word):\n","    try:\n","        return model[word]\n","    except KeyError:\n","        # Handle the case when one or both words are not in the vocabulary\n","        return np.zeros(300)\n","\n","Train_Data = []\n","\n","max_words = 10\n","print(\"Processing train articles ...\")\n","# Iterate over each article\n","for article in X_train:\n","    # Create a matrix for the current article\n","    article_matrix = [score(word2vec, word) for word in article.split()[:10]]\n","    # Add the matrix to the list\n","    padding_size = max_words - len(article_matrix)\n","    if padding_size > 0:\n","        article_matrix += [np.zeros(300)] * padding_size\n","    Train_Data.append(np.asarray(article_matrix).flatten())\n","\n","\n","Train_Data = np.array(Train_Data)\n","\n","print(\"Articles processed!\")\n","\n","model = LogisticRegression(max_iter=1000)\n","\n","model.fit(Train_Data, y_train)"],"metadata":{"id":"A2YFsdhOhG6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Val_Data = []\n","print(\"Processing val articles ...\")\n","# Iterate over each article\n","for article in X_val:\n","    # Create a matrix for the current article\n","    article_matrix = [score(word2vec, word) for word in article.split()[:10]]\n","    # Add the matrix to the list\n","\n","    padding_size = max_words - len(article_matrix)\n","    if padding_size > 0:\n","        article_matrix += [np.zeros(300)] * padding_size\n","    Val_Data.append(np.asarray(article_matrix).flatten())\n","\n","Val_Data = np.array(Val_Data)\n","\n","print(\"Articles processed!\")\n","\n","predictions = model.predict(Val_Data)\n","\n","\n","acc = accuracy_score(y_val, predictions)\n","prec = precision_score(y_val, predictions)\n","rec = recall_score(y_val, predictions)\n","f1 = f1_score(y_val, predictions)\n","\n","\n","print('Scores for Baseline 2:')\n","print('Accuracy: ', acc)\n","print('Precision: ', prec)\n","print('Recall: ', rec)\n","print('F1 Score: ', f1)"],"metadata":{"id":"nq4eJC8hj3Pl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Test_Data = []\n","print(\"Processing test articles ...\")\n","# Iterate over each article\n","for article in X_test:\n","    # Create a matrix for the current article\n","    article_matrix = [score(word2vec, word) for word in article.split()[:10]]\n","    # Add the matrix to the list\n","    padding_size = max_words - len(article_matrix)\n","    if padding_size > 0:\n","        article_matrix += [np.zeros(300)] * padding_size\n","\n","    Test_Data.append(np.asarray(article_matrix).flatten())\n","\n","Test_Data = np.array(Test_Data)\n","\n","print(\"Articles processed!\")\n","\n","predictions = model.predict(Test_Data)\n","\n","\n","acc = accuracy_score(y_test, predictions)\n","prec = precision_score(y_test, predictions)\n","rec = recall_score(y_test, predictions)\n","f1 = f1_score(y_test, predictions)\n","\n","print('Scores for Baseline 2:')\n","print('Accuracy: ', acc)\n","print('Precision: ', prec)\n","print('Recall: ', rec)\n","print('F1 Score: ', f1)"],"metadata":{"id":"1MX536gUlC0Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ebV0fQqCJiwX"},"execution_count":null,"outputs":[]}]}